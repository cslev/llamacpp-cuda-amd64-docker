# llamacpp-cuda-amd64-docker
This repository helps you build your own llama.cpp Docker image with CUDA support for AMD64 architectures
